{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "471df3fa",
   "metadata": {},
   "source": [
    "# Bengali Character Recognition using CNN\n",
    "\n",
    "This notebook implements a Convolutional Neural Network (CNN) to recognize Bengali characters using the Ekush dataset.\n",
    "\n",
    "The dataset contains 122 classes of Bengali characters (folders named 0 to 121), with images of size 28x28 (black background with white characters)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba90708",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e233b0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time: 2025-05-17 10:47:40\n",
      "User: bodhdipta-roy\n",
      "PyTorch Version: 2.7.0+cu128\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager as fm\n",
    "\n",
    "# Make sure required modules are imported\n",
    "if 'autocast' not in globals():\n",
    "    from torch.cuda.amp import autocast\n",
    "    \n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.amp import autocast, GradScaler  # Updated import path\n",
    "from torchvision import transforms, utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm  # Using regular tqdm instead of notebook version\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Print current system info\n",
    "print(f\"Current Time: 2025-05-17 10:47:40\")\n",
    "print(f\"User: bodhdipta-roy\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50867ad7",
   "metadata": {},
   "source": [
    "## 2. GPU Configuration and Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3358e04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU Name: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "GPU Memory: 8.59 GB\n",
      "Advanced GPU optimization settings applied for RTX 4060 8GB\n",
      "Advanced GPU optimization settings applied for RTX 4060 8GB\n"
     ]
    }
   ],
   "source": [
    "# GPU Configuration\n",
    "# Set device to GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # Get GPU details\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    \n",
    "    # Enhanced GPU optimization for RTX 4060 8GB\n",
    "    cudnn.benchmark = True  # Optimize for fixed input sizes (faster)\n",
    "    cudnn.deterministic = False  # Disable deterministic mode for better performance\n",
    "    torch.cuda.empty_cache()  # Clear GPU cache\n",
    "    \n",
    "    # Enable TF32 precision for RTX GPUs (faster than FP32, almost as accurate)\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    \n",
    "    # Set memory allocation strategy to maximize available memory\n",
    "    if hasattr(torch.cuda, 'set_per_process_memory_fraction'):\n",
    "        torch.cuda.set_per_process_memory_fraction(0.95)  # Use 95% of available GPU memory\n",
    "    \n",
    "    # Enable caching allocator for faster memory operations\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Configure JIT compilation for optimized CUDA kernels\n",
    "    if hasattr(torch._C, '_jit_set_profiling_executor'):\n",
    "        torch._C._jit_set_profiling_executor(True)\n",
    "        torch._C._jit_set_profiling_mode(True)\n",
    "    \n",
    "    print(\"Advanced GPU optimization settings applied for RTX 4060 8GB\")\n",
    "else:\n",
    "    print(\"CUDA not available. Using CPU.\")\n",
    "    \n",
    "# Function to print detailed GPU memory usage and performance\n",
    "def print_gpu_memory_stats():\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"\\n--- GPU Memory and Performance Summary ---\")\n",
    "        print(f\"  Allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "        print(f\"  Reserved:  {torch.cuda.memory_reserved() / 1e9:.2f} GB\")\n",
    "        \n",
    "        # Get detailed memory statistics for current device\n",
    "        stats = torch.cuda.memory_stats()\n",
    "        print(f\"  Active allocated: {stats.get('active_bytes.all.allocated', 0) / 1e9:.2f} GB\")\n",
    "        print(f\"  Active reserved: {stats.get('active_bytes.all.reserved', 0) / 1e9:.2f} GB\")\n",
    "        \n",
    "        # Calculate memory efficiency\n",
    "        allocated = torch.cuda.memory_allocated()\n",
    "        reserved = torch.cuda.memory_reserved()\n",
    "        if reserved > 0:\n",
    "            efficiency = (allocated / reserved) * 100\n",
    "            print(f\"  Memory efficiency: {efficiency:.2f}%\")\n",
    "        \n",
    "        # Try to get GPU utilization if pynvml is available\n",
    "        try:\n",
    "            import pynvml\n",
    "            pynvml.nvmlInit()\n",
    "            handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "            utilization = pynvml.nvmlDeviceGetUtilizationRates(handle)\n",
    "            print(f\"  GPU Utilization: {utilization.gpu}%\")\n",
    "            print(f\"  Memory Utilization: {utilization.memory}%\")\n",
    "            pynvml.nvmlShutdown()\n",
    "        except (ImportError, Exception):\n",
    "            print(f\"  GPU Utilization: Not available (pynvml not installed)\")\n",
    "        \n",
    "        print(\"------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb66f534",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47b3adf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Folder Name</th>\n",
       "      <th>Char Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>া</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ী</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ু</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ূ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Folder Name Char Name\n",
       "0            0         া\n",
       "1            1         ি\n",
       "2            2         ী\n",
       "3            3         ু\n",
       "4            4         ূ"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the CSV file containing the class labels\n",
    "# Update the path as per your system\n",
    "csv_path = '/mnt/l/Minor-Project/current/Character-Mapping.csv'  # Update this path\n",
    "\n",
    "# Update the dataset path\n",
    "dataset_path = '/mnt/l/Minor-Project/dataset'  # Update this path\n",
    "\n",
    "# Read the CSV file and display first few rows\n",
    "labels_df = pd.read_csv(csv_path)\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0396be44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV Columns: ['Folder Name', 'Char Name']\n",
      "Columns mapped successfully\n",
      "Number of existing folders: 122\n"
     ]
    }
   ],
   "source": [
    "# Check the structure of the CSV file\n",
    "print(\"CSV Columns:\", list(labels_df.columns))\n",
    "\n",
    "# Rename columns for consistency if needed\n",
    "if 'Folder Name' in labels_df.columns and 'Char Name' in labels_df.columns:\n",
    "    # Keep the original columns but create mapped columns for easier access\n",
    "    labels_df['folder_id'] = labels_df['Folder Name'].astype(int)\n",
    "    labels_df['character'] = labels_df['Char Name']\n",
    "    print(\"Columns mapped successfully\")\n",
    "else:\n",
    "    print(\"CSV does not have the expected column names. Please check the CSV structure.\")\n",
    "\n",
    "# Verify if all folders from 0 to 121 exist\n",
    "folders = [str(i) for i in range(122)]\n",
    "existing_folders = [f for f in folders if os.path.exists(os.path.join(dataset_path, f))]\n",
    "print(f\"Number of existing folders: {len(existing_folders)}\")\n",
    "missing_folders = set(folders) - set(existing_folders)\n",
    "if missing_folders:\n",
    "    print(f\"Missing folders: {missing_folders}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd883d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample folder to character mappings:\n",
      "Folder 0 -> Character ' া'\n",
      "Folder 1 -> Character ' ি'\n",
      "Folder 2 -> Character ' ী'\n",
      "Folder 3 -> Character ' ু'\n",
      "Folder 4 -> Character ' ূ'\n",
      "Folder 5 -> Character ' ৃ'\n",
      "Folder 6 -> Character ' ে'\n",
      "Folder 7 -> Character ' ৈ'\n",
      "Folder 8 -> Character ' ো'\n",
      "Folder 9 -> Character ' ৌ'\n"
     ]
    }
   ],
   "source": [
    "# Display a few examples of folder-character mappings\n",
    "print(\"Sample folder to character mappings:\")\n",
    "for i in range(min(10, len(labels_df))):\n",
    "    folder = labels_df.iloc[i]['Folder Name']\n",
    "    char = labels_df.iloc[i]['Char Name']\n",
    "    print(f\"Folder {folder} -> Character '{char}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e49e984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary for quick lookups\n",
    "folder_to_char = dict(zip(labels_df['Folder Name'], labels_df['Char Name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "630ba703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset class for the Ekush dataset\n",
    "class EkushDataset(Dataset):\n",
    "    def __init__(self, data_dir, folder_to_char, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_dir (str): Directory with all the images organized in folders from 0 to 121\n",
    "            folder_to_char (dict): Dictionary mapping folder numbers to character labels\n",
    "            transform (callable, optional): Optional transform to be applied on an image\n",
    "        \"\"\"\n",
    "        self.data_dir = data_dir\n",
    "        self.folder_to_char = folder_to_char\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Create a list of (image_path, label) tuples\n",
    "        self.images = []\n",
    "        for folder in range(122):\n",
    "            folder_path = os.path.join(data_dir, str(folder))\n",
    "            if os.path.exists(folder_path):\n",
    "                for img_name in os.listdir(folder_path):\n",
    "                    if img_name.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                        img_path = os.path.join(folder_path, img_name)\n",
    "                        self.images.append((img_path, folder))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.images[idx]\n",
    "        \n",
    "        # Open image (the images are 28x28 with black background and white foreground)\n",
    "        image = Image.open(img_path).convert('L')  # Convert to grayscale\n",
    "        \n",
    "        # Apply transformations if specified\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3da152a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 256912\n",
      "Validation set size: 55052\n",
      "Test set size: 55054\n"
     ]
    }
   ],
   "source": [
    "# Define data transformations with augmentation for training\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(10),  # Rotate by up to 10 degrees\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Small random shifts\n",
    "    transforms.ToTensor(),  # Convert to tensor (scales to [0, 1])\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "# Transformations for validation and testing\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Create the full dataset\n",
    "full_dataset = EkushDataset(dataset_path, folder_to_char, transform=train_transform)\n",
    "\n",
    "# Split the dataset into training, validation, and test sets (70%, 15%, 15%)\n",
    "total_size = len(full_dataset)\n",
    "train_size = int(0.7 * total_size)\n",
    "val_size = int(0.15 * total_size)\n",
    "test_size = total_size - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    full_dataset, [train_size, val_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(seed)\n",
    ")\n",
    "\n",
    "# Override the transforms for validation and test datasets\n",
    "# We need to create new dataset instances with the different transforms\n",
    "val_dataset.dataset = EkushDataset(dataset_path, folder_to_char, transform=eval_transform)\n",
    "val_dataset.indices = val_dataset.indices[:len(val_dataset)]\n",
    "\n",
    "test_dataset.dataset = EkushDataset(dataset_path, folder_to_char, transform=eval_transform)\n",
    "test_dataset.indices = test_dataset.indices[:len(test_dataset)]\n",
    "\n",
    "# Create data loaders with optimized settings for RTX 4060 8GB GPU\n",
    "batch_size = 256  # Increased batch size for RTX 4060 8GB\n",
    "num_workers = 6   # Increased worker threads for better CPU utilization\n",
    "prefetch_factor = 3  # Increased number of batches loaded in advance\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,  # Faster data transfer to CUDA\n",
    "    prefetch_factor=prefetch_factor,\n",
    "    persistent_workers=True,  # Keep workers alive between batches\n",
    "    drop_last=True  # Drop the last incomplete batch for better cudnn optimization\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=batch_size * 2,  # Larger batches for validation (no gradients stored)\n",
    "    shuffle=False, \n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    prefetch_factor=prefetch_factor,\n",
    "    persistent_workers=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=batch_size * 2,  # Larger batches for testing\n",
    "    shuffle=False, \n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    prefetch_factor=prefetch_factor,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(train_dataset)}\")\n",
    "print(f\"Validation set size: {len(val_dataset)}\")\n",
    "print(f\"Test set size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea5b1d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric Labels:  103 93 61 8 43 10 68 106 42 34 57 96 17 101 98 28\n",
      "First 5 keys in folder_to_char: [0, 1, 2, 3, 4]\n",
      "Example label type: <class 'int'>, value: 103\n",
      "Created new dictionary with 122 integer-keyed mappings\n",
      "Bengali Characters :  জ্ব ক্র ঙ্গ  ো  ব  অ ষ্ণ ন্ন  ফ  ঢ  ং ক্ক  এ শ্চ ক্ট  জ\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize some sample images\n",
    "def imshow(img, title=None):\n",
    "    img = img / 2 + 0.5  # Unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)), cmap='gray')\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.axis('off')\n",
    "\n",
    "# Get a batch of training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Show images\n",
    "imshow(utils.make_grid(images[:16], nrow=8), 'Sample Images')\n",
    "print('Numeric Labels: ', ' '.join(f'{labels[j]}' for j in range(16)))\n",
    "\n",
    "\n",
    "# Print the first few entries in the folder_to_char dictionary to see how keys are stored\n",
    "print(\"First 5 keys in folder_to_char:\", list(folder_to_char.keys())[:5])\n",
    "\n",
    "# Check one of the labels to see its type\n",
    "print(f\"Example label type: {type(labels[0].item())}, value: {labels[0].item()}\")\n",
    "\n",
    "# Create a new dictionary with integer keys for safer access\n",
    "folder_to_char_int = {int(k): v for k, v in folder_to_char.items() if str(k).isdigit()}\n",
    "print(f\"Created new dictionary with {len(folder_to_char_int)} integer-keyed mappings\")\n",
    "\n",
    "# Try again with the new dictionary\n",
    "print('Bengali Characters : ', ' '.join(f'{folder_to_char_int.get(labels[j].item(), \"Unknown\")}' for j in range(16)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f049d03",
   "metadata": {},
   "source": [
    "## 4. Optimized CNN Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb933f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BengaliCNN(nn.Module):\n",
    "    def __init__(self, num_classes=122):\n",
    "        super(BengaliCNN, self).__init__()\n",
    "        \n",
    "        # Use nn.Sequential for better CUDA optimization\n",
    "        self.features = nn.Sequential(\n",
    "            # First convolutional block\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),  # inplace operations save memory\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            # Second convolutional block\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            # Third convolutional block\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128 * 3 * 3, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)  # Flatten dimensions except batch\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0f61ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BengaliCNN(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Dropout2d(p=0.25, inplace=False)\n",
      "    (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): Dropout2d(p=0.25, inplace=False)\n",
      "    (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=1152, out_features=512, bias=True)\n",
      "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=512, out_features=122, bias=True)\n",
      "  )\n",
      ")\n",
      "Output shape: torch.Size([1, 122])\n"
     ]
    }
   ],
   "source": [
    "# Test the model with a random input\n",
    "model = BengaliCNN(num_classes=122)\n",
    "# Print model summary\n",
    "print(model)\n",
    "\n",
    "# Create a dummy input and test forward pass\n",
    "dummy_input = torch.randn(1, 1, 28, 28)\n",
    "model.eval()  # Set to eval mode to avoid BatchNorm1d error with batch size 1\n",
    "output = model(dummy_input)\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "\n",
    "# Move model to device (GPU if available)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)  # weight_decay for L2 regularization\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d486065d",
   "metadata": {},
   "source": [
    "## 5. Training and Evaluation Functions with Mixed Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e40db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device, scaler):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\", leave=False)\n",
    "    for images, labels in progress_bar:\n",
    "        images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad(set_to_none=True)  # More efficient than zero_grad()\n",
    "        \n",
    "        # Forward pass with mixed precision\n",
    "        with autocast('cuda'):  \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass with gradient scaling\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        # Update statistics\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': running_loss / total,\n",
    "            'accuracy': 100 * correct / total\n",
    "        })\n",
    "    \n",
    "    # Calculate epoch statistics\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100 * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(dataloader, desc=\"Validation\", leave=False)\n",
    "        for images, labels in progress_bar:\n",
    "            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            \n",
    "            # Forward pass\n",
    "            with autocast('cuda'):  \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Update statistics\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({\n",
    "                'val_loss': running_loss / total,\n",
    "                'val_accuracy': 100 * correct / total\n",
    "            })\n",
    "    \n",
    "    # Calculate epoch statistics\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100 * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62000a30",
   "metadata": {},
   "source": [
    "## 6. Training Loop with Early Stopping and GPU Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de9ba68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function with early stopping\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, \n",
    "                device, num_epochs=50, patience=10):\n",
    "    \n",
    "    # Initialize scaler for mixed precision\n",
    "    scaler = GradScaler()  # Initialize without parameters\n",
    "    \n",
    "    # Initialize history dictionaries\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': []\n",
    "    }\n",
    "    \n",
    "    # Initialize variables for early stopping\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        \n",
    "        # Train for one epoch\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device, scaler)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        \n",
    "        # Validate\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        # Update learning rate based on validation loss\n",
    "        old_lr = optimizer.param_groups[0]['lr']\n",
    "        scheduler.step(val_loss)\n",
    "        new_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        if new_lr != old_lr:\n",
    "            print(f\"Learning rate reduced from {old_lr:.6f} to {new_lr:.6f}\")\n",
    "        \n",
    "        # Print epoch statistics\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "        \n",
    "        # Calculate GPU memory usage\n",
    "        if torch.cuda.is_available():\n",
    "            mem_allocated = torch.cuda.memory_allocated() / 1e9\n",
    "            mem_reserved = torch.cuda.memory_reserved() / 1e9\n",
    "            print(f\"GPU Memory: Allocated {mem_allocated:.2f}GB, Reserved {mem_reserved:.2f}GB\")\n",
    "            \n",
    "        # Check for improvement\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            print(f\"Validation loss improved to {best_val_loss:.4f}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"Validation did not improve. Patience: {patience_counter}/{patience}\")\n",
    "            \n",
    "        # Early stopping\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "            break\n",
    "            \n",
    "        print(\"------------------------------\")\n",
    "    \n",
    "    # Load the best model\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        print(\"Loaded the best model based on validation loss\")\n",
    "        \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9591ecd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "\n",
      "--- GPU Memory and Performance Summary ---\n",
      "  Allocated: 0.00 GB\n",
      "  Reserved:  0.02 GB\n",
      "  Active allocated: 0.00 GB\n",
      "  Active reserved: 0.00 GB\n",
      "  Memory efficiency: 13.00%\n",
      "  GPU Utilization: 0%\n",
      "  Memory Utilization: 10%\n",
      "------------------------------------------\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d3f7c3efd9b441b9af054ef959a4fae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1003 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "autocast.__init__() missing 1 required positional argument: 'device_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m print_gpu_memory_stats()  \u001b[38;5;66;03m# Print initial GPU memory state\u001b[39;00m\n\u001b[32m      5\u001b[39m num_epochs = \u001b[32m20\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m model, history = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining completed.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m print_gpu_memory_stats()  \u001b[38;5;66;03m# Print final GPU memory state\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, val_loader, criterion, optimizer, scheduler, device, num_epochs, patience)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Train for one epoch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m train_loss, train_acc = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m history[\u001b[33m'\u001b[39m\u001b[33mtrain_loss\u001b[39m\u001b[33m'\u001b[39m].append(train_loss)\n\u001b[32m     28\u001b[39m history[\u001b[33m'\u001b[39m\u001b[33mtrain_acc\u001b[39m\u001b[33m'\u001b[39m].append(train_acc)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, dataloader, criterion, optimizer, device, scaler)\u001b[39m\n\u001b[32m     12\u001b[39m optimizer.zero_grad(set_to_none=\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# More efficient than zero_grad()\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Forward pass with mixed precision\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mautocast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:  \u001b[38;5;66;03m# Removed 'cuda' parameter\u001b[39;00m\n\u001b[32m     16\u001b[39m     outputs = model(images)\n\u001b[32m     17\u001b[39m     loss = criterion(outputs, labels)\n",
      "\u001b[31mTypeError\u001b[39m: autocast.__init__() missing 1 required positional argument: 'device_type'"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "print(\"Starting training...\")\n",
    "print_gpu_memory_stats()  # Print initial GPU memory state\n",
    "\n",
    "num_epochs = 20\n",
    "model, history = train_model(\n",
    "    model, train_loader, val_loader, criterion, optimizer, scheduler, \n",
    "    device, num_epochs=num_epochs, patience=10\n",
    ")\n",
    "\n",
    "print(\"Training completed.\")\n",
    "print_gpu_memory_stats()  # Print final GPU memory state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b61e58",
   "metadata": {},
   "source": [
    "## 7. Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f08e388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_loss'], label='Training Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['train_acc'], label='Training Accuracy')\n",
    "plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5429170",
   "metadata": {},
   "source": [
    "## 8. Evaluate Model on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9294230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate model on test set\n",
    "def evaluate_model(model, test_loader, criterion, device, folder_to_char):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Confusion matrix (predicted vs. true)\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(test_loader, desc=\"Testing\", leave=False)\n",
    "        for images, labels in progress_bar:\n",
    "            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            \n",
    "            # Forward pass\n",
    "            with autocast('cuda'):  \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Update statistics\n",
    "            test_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Store predictions and labels for confusion matrix\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({\n",
    "                'test_loss': test_loss / total,\n",
    "                'test_accuracy': 100 * correct / total\n",
    "            })\n",
    "    \n",
    "    # Calculate final statistics\n",
    "    test_loss = test_loss / total\n",
    "    test_acc = 100 * correct / total\n",
    "    \n",
    "    print(f\"\\nTest Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}%\")\n",
    "    \n",
    "    return test_loss, test_acc, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e54054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "print(\"Evaluating model on test set...\")\n",
    "test_loss, test_acc, all_preds, all_labels = evaluate_model(model, test_loader, criterion, device, folder_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d19637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure matplotlib to use Bengali fonts properly\n",
    "def configure_bengali_fonts():\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.font_manager as fm\n",
    "    import matplotlib as mpl\n",
    "    import subprocess\n",
    "    import os\n",
    "    \n",
    "    # Force rebuild the matplotlib font cache\n",
    "    mpl.font_manager._get_font.cache_clear()\n",
    "    mpl.font_manager.findfont.cache_clear()\n",
    "    \n",
    "    # Common locations for Bengali fonts - expanded to include more possibilities\n",
    "    bengali_font_paths = [\n",
    "        # System locations\n",
    "        \"/usr/share/fonts/truetype/noto/NotoSansBengali-Regular.ttf\",\n",
    "        \"/usr/share/fonts/truetype/noto/NotoSansBengali-Bold.ttf\",\n",
    "        \"/usr/local/share/fonts/NotoSansBengali-Regular.ttf\",\n",
    "        # User locations\n",
    "        os.path.expanduser(\"~/.fonts/NotoSansBengali-Regular.ttf\"),\n",
    "        os.path.expanduser(\"~/.fonts/NotoSansBengali-VariableFont_wdth,wght.ttf\"),\n",
    "        os.path.expanduser(\"~/.local/share/fonts/NotoSansBengali-Regular.ttf\"),\n",
    "        # Noto Serif options\n",
    "        \"/usr/share/fonts/truetype/noto/NotoSerifBengali-Regular.ttf\",\n",
    "        \"/usr/share/fonts/truetype/noto/NotoSerifBengali-Bold.ttf\",\n",
    "        # Lohit options  \n",
    "        \"/usr/share/fonts/truetype/lohit-bengali/Lohit-Bengali.ttf\",\n",
    "        # Windows locations (for WSL users)\n",
    "        \"/mnt/c/Windows/Fonts/Nirmala.ttf\",  # Windows Bengali font\n",
    "        \"/mnt/c/Windows/Fonts/NirmalaB.ttf\",\n",
    "        # Other common locations\n",
    "        \"/usr/share/fonts/opentype/noto/NotoSansBengali-Regular.otf\",\n",
    "        \"/usr/share/fonts/noto-cjk/NotoSansBengali-Regular.ttf\"\n",
    "    ]\n",
    "    \n",
    "    print(\"Searching for Bengali fonts...\")\n",
    "    \n",
    "    # First try: Check if any of the specified fonts exist\n",
    "    bengali_font_path = None\n",
    "    for font_path in bengali_font_paths:\n",
    "        if os.path.exists(font_path):\n",
    "            bengali_font_path = font_path\n",
    "            print(f\"Found Bengali font: {font_path}\")\n",
    "            # Add this font specifically\n",
    "            fm.fontManager.addfont(font_path)\n",
    "            font_props = fm.FontProperties(fname=font_path)\n",
    "            font_name = font_props.get_name()\n",
    "            print(f\"Using Bengali font: {font_name}\")\n",
    "            break\n",
    "    \n",
    "    # Second try: If we couldn't find a specific font, try to find any Bengali font on the system\n",
    "    if bengali_font_path is None:\n",
    "        try:\n",
    "            # Try to locate Bengali fonts using fc-list (fontconfig)\n",
    "            print(\"Searching system for Bengali fonts using fc-list...\")\n",
    "            result = subprocess.run(['fc-list', ':lang=bn'], capture_output=True, text=True)\n",
    "            font_lines = result.stdout.strip().split('\\n')\n",
    "            \n",
    "            if font_lines and font_lines[0]:  # If we found any Bengali fonts\n",
    "                for line in font_lines:\n",
    "                    if \":\" in line:  # fc-list output format: path:name:properties\n",
    "                        path = line.split(':')[0]\n",
    "                        if os.path.exists(path):\n",
    "                            bengali_font_path = path\n",
    "                            print(f\"Found Bengali font via fc-list: {path}\")\n",
    "                            # Add this font\n",
    "                            fm.fontManager.addfont(path)\n",
    "                            font_props = fm.FontProperties(fname=path)\n",
    "                            font_name = font_props.get_name()\n",
    "                            print(f\"Using Bengali font: {font_name}\")\n",
    "                            break\n",
    "        except Exception as e:\n",
    "            print(f\"Error searching for Bengali fonts: {e}\")\n",
    "    \n",
    "    # If we found a Bengali font, configure matplotlib to use it\n",
    "    if bengali_font_path:\n",
    "        font_props = fm.FontProperties(fname=bengali_font_path)\n",
    "        \n",
    "        # Create a custom font configuration\n",
    "        plt.rcParams['font.family'] = 'sans-serif'\n",
    "        plt.rcParams['font.sans-serif'] = [font_props.get_name(), 'Nirmala UI', 'Noto Sans Bengali', 'Lohit Bengali', 'sans-serif']\n",
    "        \n",
    "        # Update rcParams to ensure font is used\n",
    "        plt.rcParams['axes.unicode_minus'] = False  # Proper minus sign\n",
    "        \n",
    "        print(f\"Matplotlib configured to use Bengali font: {font_props.get_name()}\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"WARNING: Could not find any Bengali fonts. Text may not render correctly.\")\n",
    "        print(\"Consider installing Noto Sans Bengali font: sudo apt-get install fonts-noto-cjk\")\n",
    "        return False\n",
    "    \n",
    "    if bengali_font:\n",
    "        # Set the specific font family\n",
    "        font_props = fm.FontProperties(fname=bengali_font)\n",
    "        plt.rcParams['font.family'] = font_props.get_name()\n",
    "        return True\n",
    "    else:\n",
    "        print(\"Could not find any of the specified Bengali fonts\")\n",
    "        return False\n",
    "\n",
    "# Update the visualization function to use the configured Bengali fonts\n",
    "def visualize_bengali_predictions(model, test_loader, device, folder_to_char, num_samples=16):\n",
    "    \"\"\"Visualize predictions with the specific Bengali fonts you have installed\"\"\"\n",
    "    import os\n",
    "    \n",
    "    # Configure the Bengali fonts first\n",
    "    fonts_configured = configure_bengali_fonts()\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # Get a batch of test images\n",
    "    dataiter = iter(test_loader)\n",
    "    images, labels = next(dataiter)\n",
    "    \n",
    "    # Make predictions\n",
    "    with torch.no_grad():\n",
    "        images_cuda = images.to(device, non_blocking=True)\n",
    "        with autocast('cuda'):\n",
    "            outputs = model(images_cuda)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "    \n",
    "    # Display the results\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    for i in range(min(num_samples, len(images))):\n",
    "        ax = plt.subplot(2, num_samples//2, i+1)\n",
    "        img = images[i] / 2 + 0.5  # Unnormalize\n",
    "        plt.imshow(img.numpy().squeeze(), cmap='gray')\n",
    "        \n",
    "        # Get the predicted and true labels\n",
    "        pred_label = predicted[i].item()\n",
    "        true_label = labels[i].item()\n",
    "        \n",
    "        # Get the corresponding Bengali characters\n",
    "        pred_char = folder_to_char.get(pred_label, folder_to_char.get(str(pred_label), f\"Class {pred_label}\"))\n",
    "        true_char = folder_to_char.get(true_label, folder_to_char.get(str(true_label), f\"Class {true_label}\"))\n",
    "        \n",
    "        # Display both the Bengali character and class number \n",
    "        # (using class number as fallback if rendering fails)\n",
    "        title = f\"Pred: {pred_char} ({pred_label})\\nTrue: {true_char} ({true_label})\"\n",
    "        \n",
    "        # Color the title based on whether the prediction is correct\n",
    "        color = 'green' if pred_label == true_label else 'red'\n",
    "        \n",
    "        # Set the title with appropriate font properties\n",
    "        plt.title(title, color=color, fontsize=10)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return predicted.cpu().numpy(), labels.cpu().numpy()\n",
    "# Visualize predictions\n",
    "visualize_predictions(model, test_loader, device, folder_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9ca8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Bengali font rendering\n",
    "def test_bengali_rendering():\n",
    "    # First configure the Bengali fonts\n",
    "    font_configured = configure_bengali_fonts()\n",
    "    \n",
    "    # Sample Bengali text\n",
    "    bengali_text = 'বাংলা'  # \"Bangla\" in Bengali\n",
    "    bengali_numbers = '০১২৩৪৫৬৭৮৯'  # Bengali digits 0-9\n",
    "    bengali_vowels = 'অ আ ই ঈ উ ঊ ঋ এ ঐ ও ঔ'  # Bengali vowels\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Test 1: Basic text rendering\n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.text(0.5, 0.5, bengali_text, fontsize=24, ha='center')\n",
    "    plt.title('Basic Bengali Text', fontsize=12)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Test 2: Bengali numbers\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.text(0.5, 0.5, bengali_numbers, fontsize=20, ha='center')\n",
    "    plt.title('Bengali Digits (0-9)', fontsize=12)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Test 3: Bengali vowels\n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.text(0.5, 0.5, bengali_vowels, fontsize=18, ha='center')\n",
    "    plt.title('Bengali Vowels', fontsize=12)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Report font status\n",
    "    if font_configured:\n",
    "        print(\"Bengali font configuration appears successful!\")\n",
    "    else:\n",
    "        print(\"Bengali font configuration may have issues. Please install Bengali fonts to render properly.\")\n",
    "    \n",
    "    return font_configured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0706129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions_simple(model, test_loader, device, num_samples=16):\n",
    "    \"\"\"Visualize predictions with class numbers instead of Bengali characters\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Get a batch of test images\n",
    "    dataiter = iter(test_loader)\n",
    "    images, labels = next(dataiter)\n",
    "    \n",
    "    # Make predictions\n",
    "    with torch.no_grad():\n",
    "        images_cuda = images.to(device, non_blocking=True)\n",
    "        with autocast('cuda'):  \n",
    "            outputs = model(images_cuda)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "    \n",
    "    # Display the results\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    for i in range(min(num_samples, len(images))):\n",
    "        plt.subplot(2, num_samples//2, i+1)\n",
    "        img = images[i] / 2 + 0.5  # Unnormalize\n",
    "        plt.imshow(img.numpy().squeeze(), cmap='gray')\n",
    "        \n",
    "        # Get the predicted and true labels\n",
    "        pred_label = predicted[i].item()\n",
    "        true_label = labels[i].item()\n",
    "        \n",
    "        title = f\"Pred: Class {pred_label}\\nTrue: Class {true_label}\"\n",
    "        \n",
    "        # Color the title based on whether the prediction is correct\n",
    "        color = 'green' if pred_label == true_label else 'red'\n",
    "        plt.title(title, color=color)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return predicted.cpu().numpy(), labels.cpu().numpy()\n",
    "# Visualize predictions with class numbers\n",
    "predicted, labels = visualize_predictions_simple(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57eec2c0",
   "metadata": {},
   "source": [
    "## 9. Save and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db21c257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "def save_model(model, filepath):\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'model_architecture': str(model),  # Save model architecture description\n",
    "        'num_classes': 122,\n",
    "        'timestamp': \"2025-05-17 10:47:40\",\n",
    "        'user': 'bodhdipta-roy'\n",
    "    }, filepath)\n",
    "    print(f\"Model saved to {filepath}\")\n",
    "\n",
    "# Load the model\n",
    "def load_model(model, filepath, device):\n",
    "    checkpoint = torch.load(filepath, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    print(f\"Model loaded from {filepath}\")\n",
    "    print(f\"Model was saved on {checkpoint.get('timestamp', 'unknown date')}\")\n",
    "    return model\n",
    "\n",
    "# Save the model\n",
    "save_model(model, 'bengali_cnn_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e475ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model (for demonstration)\n",
    "loaded_model = BengaliCNN(num_classes=122)\n",
    "loaded_model = load_model(loaded_model, 'bengali_cnn_model.pth', device)\n",
    "\n",
    "# Quick verification that the loaded model works\n",
    "test_loss, test_acc, _, _ = evaluate_model(loaded_model, test_loader, criterion, device, folder_to_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d831350",
   "metadata": {},
   "source": [
    "## 10. Inference Example with GPU Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f8ed7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_image(model, image_path, device, folder_to_char, transform=None):\n",
    "    # Default transform if none provided\n",
    "    if transform is None:\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,))\n",
    "        ])\n",
    "    \n",
    "    # Load and preprocess the image\n",
    "    image = Image.open(image_path).convert('L')  # Convert to grayscale\n",
    "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "    \n",
    "    # Move to device and get prediction\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        image = image.to(device, non_blocking=True)\n",
    "        with autocast('cuda'):  \n",
    "            output = model(image)\n",
    "        probabilities = F.softmax(output, dim=1)\n",
    "        confidence, predicted_class = torch.max(probabilities, 1)\n",
    "    \n",
    "    # Get the predicted class and confidence\n",
    "    pred_class = predicted_class.item()\n",
    "    confidence = confidence.item() * 100\n",
    "    \n",
    "    # Get the character\n",
    "    pred_character = folder_to_char.get(str(pred_class), f\"Unknown (Class {pred_class})\")\n",
    "    \n",
    "    # Display the image with prediction\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    img = image.cpu().squeeze() / 2 + 0.5  # Unnormalize\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f\"Prediction: {pred_character}\\nConfidence: {confidence:.2f}%\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    return pred_class, confidence, pred_character\n",
    "\n",
    "# Example usage (replace with an actual image path)\n",
    "# sample_image_path = 'path_to_sample_image.png'\n",
    "# pred_class, confidence, pred_character = predict_single_image(model, sample_image_path, device, folder_to_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d956df6e",
   "metadata": {},
   "source": [
    "## 11. Performance Analysis and Improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f0d95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Generate classification report\n",
    "# Use folder names for target names\n",
    "class_names = [str(i) for i in range(122)]\n",
    "report = classification_report(all_labels, all_preds, target_names=class_names)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# If there are too many classes, we can plot a subset of the confusion matrix\n",
    "# Get the classes with highest confusion\n",
    "conf_mat = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Find the most confused classes (excluding the diagonal)\n",
    "conf_mat_no_diag = conf_mat.copy()\n",
    "np.fill_diagonal(conf_mat_no_diag, 0)\n",
    "most_confused = np.unravel_index(np.argsort(conf_mat_no_diag.ravel())[-10:], conf_mat_no_diag.shape)\n",
    "confused_classes = set(most_confused[0]) | set(most_confused[1])\n",
    "confused_classes = sorted(list(confused_classes))\n",
    "\n",
    "# Create a reduced confusion matrix with the most confused classes\n",
    "if len(confused_classes) > 0:\n",
    "    # Filter labels and predictions to only include the confused classes\n",
    "    mask = np.isin(all_labels, confused_classes)\n",
    "    filtered_labels = np.array(all_labels)[mask]\n",
    "    filtered_preds = np.array(all_preds)[mask]\n",
    "    \n",
    "    # Create a confusion matrix with just these classes\n",
    "    conf_mat_reduced = confusion_matrix(filtered_labels, filtered_preds, labels=confused_classes)\n",
    "    \n",
    "    # Display the reduced confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    display_labels = [f\"{i} ({folder_to_char.get(str(i), 'Unknown')})\" for i in confused_classes]\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=conf_mat_reduced, display_labels=display_labels)\n",
    "    disp.plot(cmap='viridis', xticks_rotation=45)\n",
    "    plt.title('Confusion Matrix for Most Confused Classes')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a53bc6b",
   "metadata": {},
   "source": [
    "## 12. GPU Training Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c9193c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze training time per epoch (if you recorded this data)\n",
    "if hasattr(history, 'epoch_times'):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(history.epoch_times)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Time (s)')\n",
    "    plt.title('Training Time per Epoch')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Print GPU utilization summary\n",
    "print_gpu_memory_stats()\n",
    "\n",
    "# Test GPU inference speed\n",
    "def measure_inference_speed(model, device, input_size=(1, 1, 28, 28), num_runs=100):\n",
    "    model.eval()\n",
    "    dummy_input = torch.randn(input_size, device=device)\n",
    "    \n",
    "    # Warm-up runs\n",
    "    with torch.no_grad():\n",
    "        for _ in range(10):\n",
    "            with autocast('cuda'):  \n",
    "                _ = model(dummy_input)\n",
    "    \n",
    "    # Measure time\n",
    "    torch.cuda.synchronize()\n",
    "    start_time = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_runs):\n",
    "            with autocast('cuda'): \n",
    "                _ = model(dummy_input)\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    end_time = time.time()\n",
    "    \n",
    "    avg_time = (end_time - start_time) / num_runs\n",
    "    return avg_time\n",
    "\n",
    "# Measure inference speed for single images and batches\n",
    "single_img_time = measure_inference_speed(model, device, (1, 1, 28, 28))\n",
    "batch_time = measure_inference_speed(model, device, (64, 1, 28, 28))\n",
    "\n",
    "print(f\"Single image inference: {single_img_time*1000:.2f} ms\")\n",
    "print(f\"Batch inference (64 images): {batch_time*1000:.2f} ms\")\n",
    "print(f\"Average time per image in batch: {batch_time*1000/64:.2f} ms\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
