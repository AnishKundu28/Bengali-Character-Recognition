{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5941e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from matplotlib import rcParams\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d1bcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bengali Handwritten Character Recognition using Ekush Dataset\n",
    "# Complete Implementation in Jupyter Notebook\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "# Display PyTorch version and GPU availability\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Step 1: Define paths and parameters\n",
    "# You'll need to update these paths according to your dataset location\n",
    "BASE_PATH = r'C:\\Users\\KIIT\\Desktop\\minor\\dataset\\dataset'  # Update this path\n",
    "METADATA_PATH = os.path.join(BASE_PATH, r\"C:\\Users\\KIIT\\Desktop\\minor\\metaData_img.csv\")  # Update if filename is different\n",
    "IMG_SIZE = 28  # We'll resize all images to 28x28\n",
    "BATCH_SIZE = 28\n",
    "EPOCHS = 15\n",
    "NUM_CLASSES = 122  # 122 Bengali character classes (0-121)\n",
    "\n",
    "# Step 2: Load metadata\n",
    "# The metadata file maps folder names to actual Bengali characters\n",
    "metadata = pd.read_csv(METADATA_PATH)\n",
    "print(\"Metadata information:\")\n",
    "print(metadata.head())\n",
    "\n",
    "# Create a mapping from class index to Bengali character name\n",
    "class_to_char = dict(zip(metadata['Folder Name'].astype(int), metadata['Char Name']))\n",
    "print(f\"Sample mapping - Class 0: {class_to_char[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d69842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: PyTorch Dataset for loading and preprocessing images\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Constants (define these as per your dataset)\n",
    "IMG_SIZE = 64  # Example image size, adjust as needed\n",
    "NUM_CLASSES = 10  # Example number of classes, adjust as needed\n",
    "\n",
    "# Mapping from class index to character (define as per your dataset)\n",
    "class_to_char = {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'J'}\n",
    "\n",
    "# BengaliCharacterDataset class\n",
    "class BengaliCharacterDataset(Dataset):\n",
    "    def __init__(self, base_path, class_to_char, img_size=IMG_SIZE, transform=None):\n",
    "        self.base_path = base_path\n",
    "        self.class_to_char = class_to_char\n",
    "        self.img_size = img_size\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        self.labels = []\n",
    "        self._load_samples()\n",
    "\n",
    "    def _load_samples(self):\n",
    "        for class_idx in range(NUM_CLASSES):\n",
    "            class_dir = os.path.join(self.base_path, str(class_idx))\n",
    "            if not os.path.exists(class_dir):\n",
    "                print(f\"Warning: Directory for class {class_idx} not found at {class_dir}\")\n",
    "                continue\n",
    "            img_files = [f for f in os.listdir(class_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            for img_file in img_files:\n",
    "                img_path = os.path.join(class_dir, img_file)\n",
    "                self.samples.append(img_path)\n",
    "                self.labels.append(class_idx)\n",
    "        print(f\"Loaded {len(self.samples)} images.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.samples[idx]\n",
    "        label = self.labels[idx]\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('L')  # Grayscale\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            else:\n",
    "                img = transforms.ToTensor()(img)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            img = torch.zeros((1, self.img_size, self.img_size))\n",
    "        return img, label\n",
    "\n",
    "# Example transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Example usage:\n",
    "# dataset = BengaliCharacterDataset(base_path='path_to_your_data', class_to_char=class_to_char, transform=transform)\n",
    "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf0ce22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Load and prepare data using PyTorch Dataset and DataLoader\n",
    "\n",
    "dataset = BengaliCharacterDataset(BASE_PATH, class_to_char, img_size=IMG_SIZE, transform=transform)\n",
    "\n",
    "# Split indices for train, val, test\n",
    "indices = np.arange(len(dataset))\n",
    "train_idx, temp_idx, _, temp_labels = train_test_split(\n",
    "    indices, dataset.labels, test_size=0.3, random_state=42, stratify=dataset.labels\n",
    ")\n",
    "val_idx, test_idx = train_test_split(\n",
    "    temp_idx, test_size=0.5, random_state=42, stratify=temp_labels\n",
    ")\n",
    "\n",
    "# Subset Datasets\n",
    "from torch.utils.data import Subset\n",
    "train_dataset = Subset(dataset, train_idx)\n",
    "val_dataset = Subset(dataset, val_idx)\n",
    "test_dataset = Subset(dataset, test_idx)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Train set size: {len(train_dataset)}\")\n",
    "print(f\"Validation set size: {len(val_dataset)}\")\n",
    "print(f\"Test set size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f057ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Exploratory Data Analysis\n",
    "# Visualize some sample images from the PyTorch Dataset\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i in range(9):\n",
    "    img, label = dataset[i]\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.imshow(img.squeeze().numpy(), cmap='gray')\n",
    "    plt.title(f\"Class: {label} ({class_to_char.get(label, 'Unknown')})\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig('sample_bengali_characters.png')\n",
    "plt.show()\n",
    "\n",
    "# Check class distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x=dataset.labels)\n",
    "plt.title('Distribution of Classes')\n",
    "plt.xlabel('Class Index')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.savefig('class_distribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b249a34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Dataset splitting already handled above for PyTorch\n",
    "# Labels are integer class indices (no one-hot encoding needed for PyTorch CrossEntropyLoss)\n",
    "\n",
    "print(f\"Training set size: {len(train_dataset)}\")\n",
    "print(f\"Validation set size: {len(val_dataset)}\")\n",
    "print(f\"Test set size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5787307f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Data Augmentation using torchvision transforms\n",
    "aug_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomAffine(0, translate=(0.1, 0.1)),\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.9, 1.1)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Visualize data augmentation examples\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i in range(9):\n",
    "    img, label = dataset[i]\n",
    "    aug_img = aug_transform(transforms.ToPILImage()(img))\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.imshow(aug_img.squeeze().numpy(), cmap='gray')\n",
    "    plt.title(f\"Augmented Sample\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig('augmented_samples.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacb4735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "\n",
    "# Step 8: Define the CNN Model in PyTorch\n",
    "class BengaliCNN(nn.Module):\n",
    "    def __init__(self, num_classes=NUM_CLASSES):\n",
    "        super(BengaliCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.4),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 3 * 3, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Create the model\n",
    "model = BengaliCNN(num_classes=NUM_CLASSES)\n",
    "\n",
    "# Move model to device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Print model summary\n",
    "def print_model_summary(model, input_size=(1, IMG_SIZE, IMG_SIZE)):\n",
    "    summary(model, input_size)\n",
    "\n",
    "try:\n",
    "    print_model_summary(model)\n",
    "except Exception as e:\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dab765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# Step 9: Define optimizer, loss function, and learning rate scheduler for PyTorch\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=3, min_lr=1e-5, verbose=True)\n",
    "\n",
    "# Early stopping utility\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=False):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "        self.verbose = verbose\n",
    "        self.best_state = None\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.best_loss is None or val_loss < self.best_loss:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            self.best_state = model.state_dict()\n",
    "            if self.verbose:\n",
    "                print(f\"Validation loss improved to {val_loss:.4f}. Saving model.\")\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87680fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Train the model (PyTorch training loop)\n",
    "early_stopping = EarlyStopping(patience=5, verbose=True)\n",
    "best_val_acc = 0.0\n",
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    train_loss = running_loss / total\n",
    "    train_acc = correct / total\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct, val_total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "    val_loss = val_loss / val_total\n",
    "    val_acc = val_correct / val_total\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "    early_stopping(val_loss, model)\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'best_bengali_char_model.pth')\n",
    "        print(\"Best model saved.\")\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        model.load_state_dict(early_stopping.best_state)\n",
    "        break\n",
    "\n",
    "# Save training history for plotting\n",
    "history = {\n",
    "    'train_loss': train_losses,\n",
    "    'val_loss': val_losses,\n",
    "    'train_acc': train_accuracies,\n",
    "    'val_acc': val_accuracies\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b456be28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Visualize training history\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_acc'], label='Training Accuracy')\n",
    "plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['train_loss'], label='Training Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531f1fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 12: Evaluate on test set (PyTorch)\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_correct, test_total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "        test_total += labels.size(0)\n",
    "test_loss = test_loss / test_total\n",
    "test_acc = test_correct / test_total\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "print(f\"Test loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447331e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 13: Make predictions on test set (PyTorch)\n",
    "model.eval()\n",
    "y_pred = []\n",
    "y_true = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "        y_true.extend(labels.numpy())\n",
    "y_pred = np.array(y_pred)\n",
    "y_true = np.array(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae6ae4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 14: Classification report\n",
    "print(\"Classification Report:\")\n",
    "class_report = classification_report(y_true, y_pred)\n",
    "print(class_report)\n",
    "\n",
    "# Save the classification report to file\n",
    "with open('classification_report.txt', 'w') as f:\n",
    "    f.write(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9995ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 15: Confusion Matrix (for a subset of classes)\n",
    "# We'll visualize a subset due to the large number of classes\n",
    "plt.figure(figsize=(12, 10))\n",
    "subset_size = 20  # Visualize first 20 classes\n",
    "subset_indices = np.where((y_true < subset_size) & (y_pred < subset_size))[0]\n",
    "\n",
    "cm_subset = confusion_matrix(\n",
    "    y_true[subset_indices],\n",
    "    y_pred[subset_indices],\n",
    "    labels=range(subset_size)\n",
    ")\n",
    "\n",
    "# Normalize confusion matrix\n",
    "cm_normalized = cm_subset.astype('float') / cm_subset.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Create heatmap\n",
    "sns.heatmap(\n",
    "    cm_normalized,\n",
    "    annot=True,\n",
    "    fmt='.2f',\n",
    "    cmap='Blues',\n",
    "    xticklabels=[class_to_char.get(i, str(i)) for i in range(subset_size)],\n",
    "    yticklabels=[class_to_char.get(i, str(i)) for i in range(subset_size)]\n",
    ")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix (First 20 Classes)')\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452566ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 16: Visualize some model predictions\n",
    "\n",
    "def visualize_predictions(X_data, y_true, y_pred, num_samples=10):\n",
    "    \"\"\"Visualize model predictions alongside true labels\"\"\"\n",
    "    indices = np.random.choice(len(X_data), num_samples, replace=False)\n",
    "\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    for i, idx in enumerate(indices):\n",
    "        plt.subplot(2, 5, i+1)\n",
    "        img = X_data[idx]\n",
    "        if isinstance(img, torch.Tensor):\n",
    "            img = img.squeeze().numpy()\n",
    "        plt.imshow(img, cmap='gray')\n",
    "\n",
    "        true_label = class_to_char.get(y_true[idx], str(y_true[idx]))\n",
    "        pred_label = class_to_char.get(y_pred[idx], str(y_pred[idx]))\n",
    "\n",
    "        title = f\"True: {true_label}\\nPred: {pred_label}\"\n",
    "        color = \"green\" if y_true[idx] == y_pred[idx] else \"red\"\n",
    "\n",
    "        plt.title(title, color=color)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('prediction_samples.png')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize predictions\n",
    "visualize_predictions([dataset[i][0] for i in test_idx], y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77fe7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 17: Save the model for future use\n",
    "# Save PyTorch model\n",
    "model_path = r\"C:\\Users\\KIIT\\Desktop\\minor\\ekkush_recognition_model.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(\"Model saved successfully!\")\n",
    "\n",
    "# Step 18: Create a simple prediction function for new images using PyTorch\n",
    "def predict_bengali_character(img_path, model, class_to_char, device, img_size=IMG_SIZE):\n",
    "    \"\"\"\n",
    "    Predict the Bengali character from a given image file using PyTorch.\n",
    "\n",
    "    Args:\n",
    "        img_path: Path to the image file\n",
    "        model: Trained PyTorch model\n",
    "        class_to_char: Mapping from class index to Bengali character\n",
    "        device: torch.device\n",
    "        img_size: Size to resize image\n",
    "\n",
    "    Returns:\n",
    "        predicted_class: The predicted class index\n",
    "        confidence: Confidence score of the prediction\n",
    "        character: Bengali character (if mapping available)\n",
    "    \"\"\"\n",
    "    from PIL import Image\n",
    "    model.eval()\n",
    "    img = Image.open(img_path).convert('L')\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(img_tensor)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        confidence, predicted_class = torch.max(probs, 1)\n",
    "        predicted_class = predicted_class.item()\n",
    "        confidence = confidence.item()\n",
    "    character = class_to_char.get(predicted_class, \"Unknown\")\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f\"Predicted: {character} (Class {predicted_class})\\nConfidence: {confidence:.4f}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    return predicted_class, confidence, character\n",
    "\n",
    "# Example usage (uncomment and update path when needed)\n",
    "# model = BengaliCNN(num_classes=NUM_CLASSES)\n",
    "# model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "# model.to(device)\n",
    "# test_img_path = 'path/to/test/image.jpg'\n",
    "# predicted_class, confidence, character = predict_bengali_character(test_img_path, model, class_to_char, device)\n",
    "# print(f\"Predicted character: {character} (Class {predicted_class}) with {confidence:.2%} confidence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7584b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "rcParams['font.sans-serif'] = ['Noto Sans Bengali', 'Nirmala UI', 'Bangla Sangam MN', 'Lohit Bengali']\n",
    "\n",
    "# Function to display images with Bengali text\n",
    "def plot_bengali_predictions(images, true_labels, pred_labels, bengali_chars_dict, rows=2, cols=5, figsize=(15, 8)):\n",
    "    \"\"\"\n",
    "    Plot images with Bengali labels\n",
    "    \n",
    "    Parameters:\n",
    "    images: array of images to display\n",
    "    true_labels: true class labels (numeric)\n",
    "    pred_labels: predicted class labels (numeric)\n",
    "    bengali_chars_dict: dictionary mapping class numbers to Bengali characters\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=figsize)\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, ax in enumerate(axes):\n",
    "        if i < len(images):\n",
    "            ax.imshow(images[i], cmap='gray')\n",
    "            ax.axis('off')\n",
    "            \n",
    "            true_char = bengali_chars_dict.get(true_labels[i], str(true_labels[i]))\n",
    "            pred_char = bengali_chars_dict.get(pred_labels[i], str(pred_labels[i]))\n",
    "            \n",
    "            # Set title with both correct and predicted labels\n",
    "            ax.set_title(f'True: {true_char}\\nPred: {pred_char}', \n",
    "                        color='green' if true_labels[i] == pred_labels[i] else 'red',\n",
    "                        fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d821ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Load your trained model\n",
    "model = torch.jit.load(r\"C:\\Users\\KIIT\\Desktop\\minor\\ekkush_recognition_model.pt\")\n",
    "model.eval()\n",
    "\n",
    "# Load the class index to Bengali character mapping from CSV\n",
    "metadata_path = r\"C:\\Users\\KIIT\\Desktop\\minor\\metaData_img.csv\"  # Replace with the actual path\n",
    "metadata_df = pd.read_csv(metadata_path)\n",
    "\n",
    "# Create the class_to_char dictionary from the DataFrame\n",
    "class_to_char = dict(zip(metadata_df['Folder Name'], metadata_df['Char Name']))\n",
    "\n",
    "# Define the image transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Predict function for a single image (PyTorch version)\n",
    "def predict_image(img_path):\n",
    "    # Load and preprocess image\n",
    "    img = Image.open(img_path)\n",
    "    img_tensor = transform(img).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Predict class\n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor)\n",
    "        _, predicted_index = torch.max(output, 1)\n",
    "        confidence = torch.max(torch.nn.functional.softmax(output, dim=1))\n",
    "\n",
    "    # Get corresponding Bengali character\n",
    "    predicted_char = class_to_char.get(predicted_index.item(), \"Unknown\")\n",
    "\n",
    "    # Display result\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f\"Predicted: {predicted_char} (Class {predicted_index.item()}, {confidence.item():.2f})\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "predict_image(r\"C:\\Users\\KIIT\\Desktop\\minor\\Screenshot 2025-04-09 054801.png\")  # Replace with actual path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9438c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Load your trained model\n",
    "model = torch.jit.load(r\"C:\\Users\\KIIT\\Desktop\\minor\\ekkush_recognition_model.pt\")\n",
    "model.eval()\n",
    "\n",
    "# Load the class index to Bengali character mapping from CSV\n",
    "metadata_path = r\"C:\\Users\\KIIT\\Desktop\\minor\\metaData_img.csv\"  # Replace with the actual path\n",
    "metadata_df = pd.read_csv(metadata_path)\n",
    "\n",
    "# Create the class_to_char dictionary from the DataFrame\n",
    "class_to_char = dict(zip(metadata_df['Folder Name'], metadata_df['Char Name']))\n",
    "\n",
    "# Define the image transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Predict function for a single image (PyTorch version)\n",
    "def predict_image(img_path):\n",
    "    # Load and preprocess image\n",
    "    img = Image.open(img_path)\n",
    "    img_tensor = transform(img).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Predict class\n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor)\n",
    "        _, predicted_index = torch.max(output, 1)\n",
    "        confidence = torch.max(torch.nn.functional.softmax(output, dim=1))\n",
    "\n",
    "    # Get corresponding Bengali character\n",
    "    predicted_char = class_to_char.get(predicted_index.item(), \"Unknown\")\n",
    "\n",
    "    # Display result\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f\"Predicted: {predicted_char} (Class {predicted_index.item()}, {confidence.item():.2f})\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "predict_image(r\"C:\\Users\\KIIT\\Desktop\\minor\\Test_Img_05.jpg\")  # Replace with actual path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762fd507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Load your trained model\n",
    "model = torch.jit.load(r\"C:\\Users\\KIIT\\Desktop\\minor\\ekkush_recognition_model.pt\")\n",
    "model.eval()\n",
    "\n",
    "# Load the class index to Bengali character mapping from CSV\n",
    "metadata_path = r\"C:\\Users\\KIIT\\Desktop\\minor\\metaData_img.csv\"  # Replace with the actual path\n",
    "metadata_df = pd.read_csv(metadata_path)\n",
    "\n",
    "# Create the class_to_char dictionary from the DataFrame\n",
    "class_to_char = dict(zip(metadata_df['Folder Name'], metadata_df['Char Name']))\n",
    "\n",
    "# Define the image transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Predict function for a single image (PyTorch version)\n",
    "def predict_image(img_path):\n",
    "    # Load and preprocess image\n",
    "    img = Image.open(img_path)\n",
    "    img_tensor = transform(img).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Predict class\n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor)\n",
    "        _, predicted_index = torch.max(output, 1)\n",
    "        confidence = torch.max(torch.nn.functional.softmax(output, dim=1))\n",
    "\n",
    "    # Get corresponding Bengali character\n",
    "    predicted_char = class_to_char.get(predicted_index.item(), \"Unknown\")\n",
    "\n",
    "    # Display result\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f\"Predicted: {predicted_char} (Class {predicted_index.item()}, {confidence.item():.2f})\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "predict_image(r\"C:\\Users\\KIIT\\Pictures\\Screenshots\\Screenshot 2025-04-09 144032.png\")  # Replace with actual path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bd9706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Load your trained model\n",
    "model = torch.jit.load(r\"C:\\Users\\KIIT\\Desktop\\minor\\ekkush_recognition_model.pt\")\n",
    "model.eval()\n",
    "\n",
    "# Load the class index to Bengali character mapping from CSV\n",
    "metadata_path = r\"C:\\Users\\KIIT\\Desktop\\minor\\metaData_img.csv\"  # Replace with the actual path\n",
    "metadata_df = pd.read_csv(metadata_path)\n",
    "\n",
    "# Create the class_to_char dictionary from the DataFrame\n",
    "class_to_char = dict(zip(metadata_df['Folder Name'], metadata_df['Char Name']))\n",
    "\n",
    "# Define the image transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Predict function for a single image (PyTorch version)\n",
    "def predict_image(img_path):\n",
    "    # Load and preprocess image\n",
    "    img = Image.open(img_path)\n",
    "    img_tensor = transform(img).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Predict class\n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor)\n",
    "        _, predicted_index = torch.max(output, 1)\n",
    "        confidence = torch.max(torch.nn.functional.softmax(output, dim=1))\n",
    "\n",
    "    # Get corresponding Bengali character\n",
    "    predicted_char = class_to_char.get(predicted_index.item(), \"Unknown\")\n",
    "\n",
    "    # Display result\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f\"Predicted: {predicted_char} (Class {predicted_index.item()}, {confidence.item():.2f})\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "predict_image(r\"C:\\Users\\KIIT\\Downloads\\img4.png\")  # Replace with actual path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8a85b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Load your trained model\n",
    "model = torch.jit.load(r\"C:\\Users\\KIIT\\Desktop\\minor\\ekkush_recognition_model.pt\")\n",
    "model.eval()\n",
    "\n",
    "# Load the class index to Bengali character mapping from CSV\n",
    "metadata_path = r\"C:\\Users\\KIIT\\Desktop\\minor\\metaData_img.csv\"  # Replace with the actual path\n",
    "metadata_df = pd.read_csv(metadata_path)\n",
    "\n",
    "# Create the class_to_char dictionary from the DataFrame\n",
    "class_to_char = dict(zip(metadata_df['Folder Name'], metadata_df['Char Name']))\n",
    "\n",
    "# Define the image transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Predict function for a single image\n",
    "def predict_image(img_path):\n",
    "    # Load and preprocess image\n",
    "    img = Image.open(img_path)\n",
    "    img_tensor = transform(img).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Predict class\n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor)\n",
    "        _, predicted_index = torch.max(output, 1)\n",
    "        confidence = torch.nn.functional.softmax(output, dim=1)[0] * 100\n",
    "\n",
    "    # Get corresponding Bengali character\n",
    "    predicted_char = class_to_char.get(predicted_index.item(), \"Unknown\")\n",
    "\n",
    "    # Display result\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f\"Predicted: {predicted_char} (Class {predicted_index.item()}, {confidence[predicted_index].item():.2f}%)\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "predict_image(r\"C:\\Users\\KIIT\\Desktop\\79.jpg\")  # Replace with actual path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e658a59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Load your trained model\n",
    "model = torch.load(r\"C:\\Users\\KIIT\\Desktop\\minor\\ekkush_recognition_model.pth\")\n",
    "model.eval()\n",
    "\n",
    "# Load the class index to Bengali character mapping from CSV\n",
    "metadata_path = r\"C:\\Users\\KIIT\\Desktop\\minor\\metaData_img.csv\"  # Replace with the actual path\n",
    "metadata_df = pd.read_csv(metadata_path)\n",
    "\n",
    "# Create the class_to_char dictionary from the DataFrame\n",
    "class_to_char = dict(zip(metadata_df['Folder Name'], metadata_df['Char Name']))\n",
    "\n",
    "# Define the image transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Predict function for a single image (PyTorch version)\n",
    "def predict_image(img_path):\n",
    "    # Load and preprocess image\n",
    "    img = Image.open(img_path)\n",
    "    img_tensor = transform(img).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Predict class\n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor)\n",
    "        _, predicted_index = torch.max(output, 1)\n",
    "        confidence = torch.max(torch.nn.functional.softmax(output, dim=1))\n",
    "\n",
    "    # Get corresponding Bengali character\n",
    "    predicted_char = class_to_char.get(predicted_index.item(), \"Unknown\")\n",
    "\n",
    "    # Display result\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f\"Predicted: {predicted_char} (Class {predicted_index.item()}, {confidence.item():.2f})\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "predict_image(r\"C:\\Users\\KIIT\\Desktop\\img8.png\")  # Replace with actual path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17d1613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Load your trained model\n",
    "model = torch.jit.load(r\"C:\\Users\\KIIT\\Desktop\\minor\\ekkush_recognition_model.pt\")\n",
    "model.eval()\n",
    "\n",
    "# Load the class index to Bengali character mapping from CSV\n",
    "metadata_path = r\"C:\\Users\\KIIT\\Desktop\\minor\\metaData_img.csv\"  # Replace with the actual path\n",
    "metadata_df = pd.read_csv(metadata_path)\n",
    "\n",
    "# Create the class_to_char dictionary from the DataFrame\n",
    "class_to_char = dict(zip(metadata_df['Folder Name'], metadata_df['Char Name']))\n",
    "\n",
    "# Define the image transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Predict function for a single image (PyTorch version)\n",
    "def predict_image(img_path):\n",
    "    # Load and preprocess image\n",
    "    img = Image.open(img_path)\n",
    "    img_tensor = transform(img).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Predict class\n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor)\n",
    "        _, predicted_index = torch.max(output, 1)\n",
    "        confidence = torch.max(torch.nn.functional.softmax(output, dim=1))\n",
    "\n",
    "    # Get corresponding Bengali character\n",
    "    predicted_char = class_to_char.get(predicted_index.item(), \"Unknown\")\n",
    "\n",
    "    # Display result\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f\"Predicted: {predicted_char} (Class {predicted_index.item()}, {confidence.item():.2f})\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "predict_image(r\"C:\\Users\\KIIT\\Desktop\\img7.png\")  # Replace with actual path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3d25b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Load your trained model\n",
    "model = torch.load(r\"C:\\Users\\KIIT\\Desktop\\minor\\ekkush_recognition_model.pth\")\n",
    "model.eval()\n",
    "\n",
    "# Load the class index to Bengali character mapping from CSV\n",
    "metadata_path = r\"C:\\Users\\KIIT\\Desktop\\minor\\metaData_img.csv\"  # Replace with the actual path\n",
    "metadata_df = pd.read_csv(metadata_path)\n",
    "\n",
    "# Create the class_to_char dictionary from the DataFrame\n",
    "class_to_char = dict(zip(metadata_df['Folder Name'], metadata_df['Char Name']))\n",
    "\n",
    "# Define the image transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Predict function for a single image (PyTorch version)\n",
    "def predict_image(img_path):\n",
    "    # Load and preprocess image\n",
    "    img = Image.open(img_path)\n",
    "    img_tensor = transform(img).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Predict class\n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor)\n",
    "        _, predicted_index = torch.max(output, 1)\n",
    "        confidence = torch.max(torch.nn.functional.softmax(output, dim=1))\n",
    "\n",
    "    # Get corresponding Bengali character\n",
    "    predicted_char = class_to_char.get(predicted_index.item(), \"Unknown\")\n",
    "\n",
    "    # Display result\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f\"Predicted: {predicted_char} (Class {predicted_index.item()}, {confidence.item():.2f})\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "predict_image(r\"C:\\Users\\KIIT\\Desktop\\img9.png\")  # Replace with actual path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0401213f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Load your trained model\n",
    "model = torch.jit.load(r\"C:\\Users\\KIIT\\Desktop\\minor\\ekkush_recognition_model.pt\")\n",
    "model.eval()\n",
    "\n",
    "# Load the class index to Bengali character mapping from CSV\n",
    "metadata_path = r\"C:\\Users\\KIIT\\Desktop\\minor\\metaData_img.csv\"  # Replace with the actual path\n",
    "metadata_df = pd.read_csv(metadata_path)\n",
    "\n",
    "# Create the class_to_char dictionary from the DataFrame\n",
    "class_to_char = dict(zip(metadata_df['Folder Name'], metadata_df['Char Name']))\n",
    "\n",
    "# Define the image transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Predict function for a single image (PyTorch version)\n",
    "def predict_image(img_path):\n",
    "    # Load and preprocess image\n",
    "    img = Image.open(img_path)\n",
    "    img_tensor = transform(img).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Predict class\n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor)\n",
    "        _, predicted_index = torch.max(output, 1)\n",
    "        confidence = torch.max(torch.nn.functional.softmax(output, dim=1))\n",
    "\n",
    "    # Get corresponding Bengali character\n",
    "    predicted_char = class_to_char.get(predicted_index.item(), \"Unknown\")\n",
    "\n",
    "    # Display result\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f\"Predicted: {predicted_char} (Class {predicted_index.item()}, {confidence.item():.2f})\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "predict_image(r\"C:\\Users\\KIIT\\Desktop\\img11.png\")  # Replace with actual path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
